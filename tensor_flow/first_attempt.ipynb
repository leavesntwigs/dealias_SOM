import tensorflow as tf
import numpy as np
 
class SOM(object):
    def __init__(self, x, y, input_dim, learning_rate, radius, num_iter=111):
        
        #Initialize properties
        self._x = x
        self._y = y
        self._learning_rate = float(learning_rate)
        self._radius = float(radius)
        self._num_iter = num_iter
        self._graph = tf.Graph()
 
        #Initialize graph
        with self._graph.as_default():
            
            #Initializing variables and placeholders
            self._weights = tf.Variable(tf.random_normal([x*y, input_dim]))
            #self._weights = tf.Variable(TODO: merge [array([0,0],array([0,1],...)]tf.random_normal([x*y, 1]))
            self._locations = self._generate_index_matrix(x, y)
            self._input = tf.placeholder("float", [input_dim])
            self._iter_input = tf.placeholder("float")
 
            #Calculating BMU
            input_matix = tf.stack([self._input for i in range(x*y)])
            distances = tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self._weights, input_matix), 2), 1))
            bmu = tf.argmin(distances, 0)
            
            #Get BMU location
            mask = tf.pad(tf.reshape(bmu, [1]), np.array([[0, 1]]))
            size = tf.cast(tf.constant(np.array([1, 2])), dtype=tf.int64)
            bmu_location = tf.reshape(tf.slice(self._locations, mask, size), [2])
 
            #Calculate learning rate and radius
            decay_function = tf.subtract(1.0, tf.div(self._iter_input, self._num_iter))
            _current_learning_rate = tf.multiply(self._learning_rate, decay_function)
            _current_radius = tf.multiply(self._radius, decay_function)
 
            #Adapt learning rate to each neuron based on position
            bmu_matrix = tf.stack([bmu_location for i in range(x*y)])
            bmu_distance = tf.reduce_sum(tf.pow(tf.subtract(self._locations, bmu_matrix), 2), 1)
            neighbourhood_func = tf.exp(tf.negative(tf.div(tf.cast(bmu_distance, "float32"), tf.pow(_current_radius, 2))))
            learning_rate_matrix = tf.multiply(_current_learning_rate, neighbourhood_func)
 
            #Update all the weights
            multiplytiplier = tf.stack([tf.tile(tf.slice(
                learning_rate_matrix, np.array([i]), np.array([1])), [input_dim])
                                               for i in range(x*y)])
            delta = tf.multiply(
                multiplytiplier,
                tf.subtract(tf.stack([self._input for i in range(x*y)]), self._weights))                
                         
            new_weights = tf.add(self._weights, delta)
            self._training = tf.assign(self._weights, new_weights)                                       
 
            #Initilize session and run it
            self._sess = tf.Session()
            initialization = tf.global_variables_initializer()
            self._sess.run(initialization)
 
    def train(self, input_vects):
        for iter_no in range(self._num_iter):
            for input_vect in input_vects:
                self._sess.run(self._training,
                               feed_dict={self._input: input_vect,
                                          self._iter_input: iter_no})
 
        self._centroid_matrix = [[] for i in range(self._x)]
        self._weights_list = list(self._sess.run(self._weights))
        self._locations = list(self._sess.run(self._locations))
        for i, loc in enumerate(self._locations):
            self._centroid_matrix[loc[0]].append(self._weights_list[i])
  
    def map_input(self, input_vectors):
        return_value = []
        for vect in input_vectors:
            min_index = min([i for i in range(len(self._weights_list))],
                            key=lambda x: np.linalg.norm(vect - self._weights_list[x]))
            return_value.append((self._locations[min_index], self._weights_list[min_index]))
            # return_value.append(self._locations[min_index])
        return return_value
    
    def _generate_index_matrix(self, x,y):
        return tf.constant(np.array(list(self._iterator(x, y))))
    
    def _iterator(self, x, y):
        for i in range(x):
            for j in range(y):
                yield np.array([i, j])
                
    def get_weights(self):
      return self._weights_list
                
               
              


dummy=1

somfold = SOM(3,3,4,0.5, .5, 50)

# take the raw data
datafold =[[0,0,-10], [0,1,-8],[0,2,-7],[1,0,4],[1,1,2],[1,2,-3],[2,0,1],[2,1,-2],[2,2,-19]]
# mod velocity by 2*Nyquist, add new field velocity div 2*Nyquist
#def modthird(list3):
#  return()
#datafoldmod = map(modthird, datafold)
#print(datafoldmod)
datafoldmod =[[0,0,-10], [0,1,-8],[0,2,-7],[1,0,4],[1,1,2],[1,2,-3],[2,0,1],[2,1,-2],[2,2,-3]]
# [az,range,vel % (2*Nyquist), vel div (2*Nyquist)]
#                               ^^ not quite right
datafold_mod_div =[[0,0,-10,0], [0,1,-8,0],[0,2,-7,0],[1,0,4,0],[1,1,2,0],[1,2,-3,0],[2,0,1,0],[2,1,-2,0],[2,2,-3,1]]

# train on the moded velocity data
somfold.train(datafold_mod_div)

# convert all the groupings back to continuity by +/-  2*Nyquist ???

# map the raw data to obtain the new velocity values; keep the az,range,el,z,t, unchanged; only allow changes in the velocity
somfold.map_input(datafold_mod_div)

somfold.get_weights()





som = SOM(4,4,3,0.5, 5.0, 10)

data = [[255,0,0],[255,255,0],[0,255,0],[0,255,255],[0,0,255],[255,0,255]]

som.train(data)

som.map_input([[254,233,214]]) # beige

som.map_input(data)

def iterator(x,y):
  for i in range(x):
    for j in range(y):
      yield np.array([i,j])

def generate_index_matrix(x,y):
  return iterator(x,y) # np.array(list(iterator(x,y))
                  

mine = generate_index_matrix(3,4)
next(mine)



next(mine)

next(mine)

import tensorflow as tf

# trying to understand tf.Session
x = tf.constant([[37.0, -23.0], [1.0, 4.0]])
w = tf.Variable(tf.random_uniform([2,2]))
y = tf.matmul(x,w)
output = tf.nn.softmax(y)
init_op = w.initializer

with tf.Session() as sess:
  # Run the initializer on 'w'.
  sess.run(init_op)
  print("w = ")
  print(sess.run(w))
  
  print("output =")
  # Evaluate 'output' . 'sess.run(output)' will return a NumPy array containing
  # the result of the computation.
  print(sess.run(output))
  
  # Evaluate 'y' and 'output'. Note that 'y' will only be computed once, and its
  # result used both to return 'y_val' and as an input to the 'tf.nn.softmax()'
  # op. Both 'y_val' and 'output_val' will be NumPy arrays.
  y_val, output_val = sess.run([y, output])
  print("y_val =")
  print(y_val)
  print("output =")
  print(output_val)

report = []

for G in range(3, 13, 3):
  for L in range(1, 51, 5):
    for N in range(1, 20, 3):
    
# somfold2 = SOM(x, y, input_dim, learning_rate, radius, num_iter)
# x = |xdimension|
# y = |ydimension|
# input_dim = number in tuple
      LR = L/100.0
      somfold2 = SOM(G, G, 3, LR, N, 50)

# set the training data
      training_data = [[130, 20, -5], [130, 30, -5], [130, 30, -5], [130, 30, -5], [100, 30, -5], [130, 10, -5], [100, 20, -5], [100, 20, -5], [100, 30, -5], [130, 30, -5], [100, 10, -5], [100, 10, -5], [130, 20, 55], [130, 10, -45]]
      training_data += [[180, 20, 13], [180, 20, 13], [180, 30, 13], [180, 30, 13], [180, 30, 13], [180, 30, 13], [210, 10, 13], [210, 10, 13], [180, 10, 13], [180, 10, 13], [210, 30, 13], [180, 10, 13], [180, 10, 13], [180, 20, 13], [180, 20, 13], [210, 30, 13], [210, 30, 13], [210, 10, -27], [210, 10, -27], [210, 20, 13], [210, 20, 13], [210, 20, 73], [210, 20, 73]]
      training_data += [[60, 20, 3], [60, 10, 3], [90, 30, -17], [60, 30, 3], [30, 10, -37], [90, 10, 3], [30, 30, 3], [30, 30, 3], [30, 20, -17], [30, 20, -17], [30, 20, -17], [30, 20, -17], [30, 20, -17], [30, 20, -17], [30, 20, -17], [90, 20, 3], [60, 20, 3], [90, 30, 3], [90, 10, 3], [30, 20, 3], [60, 10, 3], [60, 30, 3], [90, 20, 3], [30, 10, -37]]

# train
      somfold2.train(training_data)

# map input
      result = somfold2.map_input([[130, 20, 55], [210, 30, 13]])

# put everything into a report
      report += [[(G,LR,N), result]]
  
print(report)



for i in range(0,len(report), 1):
  item = report[i]
  values = item[1]
  (loc1, first) = values[0]
  (loc2, second) = values[1]
#  v = first[1]
#   [az2, r2, v2] = first[2]
# print("%12.2f" % (v))
  diff = -5.0 - first[2]
  diff1 = math.sqrt(diff*diff)
  diff = 13 - second[2]
  diff2 = math.sqrt(diff*diff)
  if diff1 < 10.0 and diff2 < 10.0:
    print(item[0], "%12.2f" % (diff1), "%12.2f" % (diff2), "%12.2f" % (first[2]), "%12.2f" % (second[2]))



somfold2 = SOM(12, 3, 3, 2, 20, 100)

# set the training data

# data: no noise; one sweep; 3 patterns
#training_data = [[130, 20, -5], [130, 30, -5], [130, 10, -5], [100, 30, -5], [130, 10, -5], [100, 20, -5]]
#training_data += [[180, 10, 13], [180, 20, 13], [180, 30, 13], [210, 10, 13], [210, 20, 13], [210, 30, 13]]
#training_data += [[60, 10, 3], [60, 20, 3], [60, 30, 3], [30, 10, 3], [30, 20, 3], [30, 30, 3], [90, 10, 3], [90, 20, 3], [90, 30, 3]]

# data: 1 folding; one sweep; 3 patterns
#training_data = [[130, 20, -5], [130, 30, 15], [130, 30, -5], [130, 10, -5], [100, 30, -5], [130, 10, -5], [100, 20, -5]]
#training_data += [[180, 10, -7], [180, 10, 13], [180, 20, 13], [180, 30, 13], [210, 10, 13], [210, 20, 13], [210, 30, 13]]
#training_data += [[60, 10, 3], [60, 20, 3], [60, 30, 3], [30, 10, 3], [30, 20, 3], [30, 30, 3], [90, 10, 3], [90, 20, 3], [90, 20, 23], [90, 30, 3]]

# data: noise; 3 sweeps; 3 patterns
#training_data = [[130, 20, -5], [130, 30, -5], [130, 30, -5], [130, 30, -5], [100, 30, -5], [130, 10, -5], [100, 20, -5], [100, 20, -5], [100, 30, -5], [130, 30, -5], [100, 10, -5], [100, 10, -5], [130, 20, 55], [130, 10, -45]]
#training_data += [[180, 20, 13], [180, 20, 13], [180, 30, 13], [180, 30, 13], [180, 30, 13], [180, 30, 13], [210, 10, 13], [210, 10, 13], [180, 10, 13], [180, 10, 13], [210, 30, 13], [180, 10, 13], [180, 10, 13], [180, 20, 13], [180, 20, 13], [210, 30, 13], [210, 30, 13], [210, 10, -27], [210, 10, -27], [210, 20, 13], [210, 20, 13], [210, 20, 73], [210, 20, 73]]
#training_data += [[60, 20, 3], [60, 10, 3], [90, 30, -17], [60, 30, 3], [30, 10, -37], [90, 10, 3], [30, 30, 3], [30, 30, 3], [30, 20, -17], [30, 20, -17], [30, 20, -17], [30, 20, -17], [30, 20, -17], [30, 20, -17], [30, 20, -17], [90, 20, 3], [60, 20, 3], [90, 30, 3], [90, 10, 3], [30, 20, 3], [60, 10, 3], [60, 30, 3], [90, 20, 3], [30, 10, -37]]


# [[130, 20, -5], [130, 30, -5], [130, 30, -5], [130, 30, -5], [100, 30, -5], [130, 10, -5], [100, 20, -5], [100, 20, -5], [100, 30, 55], [130, 30, -85], [100, 10, -5], [100, 10, 55], [130, 20, 35], [130, 10, -5], [130, 10, -5], [130, 10, -5]]


# [[130, 20, -5, 0], [130, 30, -5, -1], [130, 30, -5, 0], [130, 30, -5, 1], [100, 30, -5, 0], [130, 10, -5, 0], [100, 20, -5, 0], [100, 20, -5, 0], [100, 30, 55, -3], [130, 30, -85, 4], [100, 10, -5, 0], [100, 10, 55, -3], [130, 20, 35, -2], [130, 10, -5, -1], [130, 10, -5, 0], [130, 10, -5, 1]]
# training_data += [[60, 20, 3, 0], [60, 10, 3, 0], [90, 30, -17, 1], [60, 30, -57, 3], [30, 10, 3, 0], [90, 10, 3, 0], [30, 30, 3, 0], [30, 30, 3, 0], [30, 20, 3, 0], [90, 20, 3, 0], [60, 20, -17, 1], [90, 30, 3, 0], [90, 10, -17, 1], [30, 20, 3, 0], [60, 10, 3, 0], [60, 30, -37, 2], [90, 20, 23, -1], [30, 10, 3, 0]]
# training_data += [[180, 20, 13, -1], [180, 20, 13, 0], [180, 30, 13, -1], [180, 30, 13, 0], [180, 30, 73, -4], [180, 30, 73, -3], [210, 10, 13, -1], [210, 10, 13, 0], [180, 10, 73, -4], [180, 10, 73, -3], [210, 30, 13, -1], [180, 10, 13, -1], [180, 10, 13, 0], [180, 20, 13, -1], [210, 30, -67, 3], [210, 30, -67, 4], [210, 10, 13, -1], [210, 20, 13, -1], [210, 20, 13, 0], [210, 20, 53, -3], [210, 20, 53, -2]]

training_data = [[261.752, 2.625, -3.0], [48.2767, 2.375, 3.0], [158.766, 3.125, -4.5], [127.752, 3.875, -1.5], [326.775, 4.125, 3.5], [116.26, 2.875, -1.5], [71.2518, 2.125, 1.5], [294.252, 2.125, 2.5], [194.268, 4.125, -7.5], [192.25, 3.875, -7.5], [19.7479, 2.125, 4.0], [252.749, 4.375, -5.5], [45.7718, 4.875, 4.5], [192.752, 3.875, -8.0], [14.7739, 2.875, 5.0], [113.766, 2.875, 5.5], [338.25, 4.375, 5.5], [249.752, 4.625, -6.5], [162.26, 3.875, -4.5], [183.255, 3.375, -5.5], [281.25, 2.375, -9.5], [39.2459, 2.375, 4.0], [248.275, 2.875, 25.0], [349.264, 4.875, 5.5], [169.247, 2.625, -5.5], [1.26617, 2.125, 4.5], [187.762, 4.625, -7.5], [4.26819, 2.625, 5.5], [210.751, 4.625, -9.0], [256.284, 2.875, -4.0], [317.758, 2.375, 2.5], [136.758, 3.625, -2.0], [208.765, 3.375, -8.0], [47.2522, 3.875, 4.0], [201.248, 2.125, -5.5], [199.753, 3.125, -5.0], [317.758, 4.375, 2.5], [81.2549, 3.375, 10.0], [289.251, 2.125, 2.0], [193.749, 2.125, -2.0], [336.272, 4.875, 4.5], [325.753, 3.875, 4.0], [160.746, 4.625, -4.5], [236.25, 4.625, 9.0], [303.253, 3.875, 0.5], [306.749, 3.375, 2.0], [305.25, 3.625, 2.5], [203.253, 4.375, -10.0], [219.754, 4.125, -9.0], [347.272, 2.375, 4.5], [144.772, 2.625, -4.5], [138.277, 3.125, -3.5], [311.745, 3.125, 3.0], [224.783, 3.875, -8.0], [192.752, 3.875, -8.0], [116.26, 3.375, 12.0], [25.2823, 4.375, 5.5], [245.248, 2.875, -5.5], [74.7455, 2.625, 2.0], [212.248, 4.625, -8.0], [16.7569, 2.875, 5.5], [208.765, 3.625, -8.5], [260.75, 4.375, -5.0], [237.263, 3.625, -6.0], [175.248, 3.625, -5.5], [349.753, 4.875, 4.5], [58.255, 3.125, 7.0], [31.7807, 3.875, 5.0], [244.745, 3.125, -6.0], [301.748, 4.875, 1.5], [200.748, 4.375, -7.5], [229.252, 4.375, -7.0], [327.25, 3.375, 3.5], [337.25, 2.625, 3.5], [320.271, 4.625, 3.0], [313.745, 3.125, 2.0], [337.758, 3.125, 4.0], [199.265, 3.875, -7.0], [234.75, 2.375, -3.5], [205.249, 4.875, -8.0], [212.764, 2.625, -6.0], [94.2545, 2.375, 1.0], [194.268, 3.125, -7.0], [300.265, 2.625, 2.0], [261.249, 2.625, -3.5], [61.2625, 4.625, 3.5], [233.281, 2.875, -6.0], [208.765, 2.875, -7.5], [205.249, 4.625, -8.0], [216.233, 2.625, -7.5], [278.251, 2.375, 10.5], [273.255, 3.125, -2.5], [305.25, 2.625, 3.0], [321.751, 4.875, 3.5], [94.7763, 4.375, 1.0], [104.247, 3.125, -10.0], [94.7763, 3.125, 1.0], [208.765, 2.375, 5.0], [119.254, 3.625, -1.0], [169.758, 2.375, -4.5]]




somfold2.train(training_data)

somfold2.map_input([[ 0.249939 , 4.875 , 6.500 ]])

#somfold2.map_input([[130, 20, -5], [210, 30, 13], [30, 30, 3]])
#print(results)
#for x in results:
#  for x2 in x:
#    print("%12.2f" % (x2))
#  print("-----")

somfold2.map_input([[130, 30, 15], [180, 10, -7], [90, 20, 23]])

weights = somfold2.get_weights()
#for x in weights:
#   for v in x:
#      print("%12.2f" % (v))
#   print("-----")
weights
#for x in range(0,3,1):
#  for y in range(0,7,1):
#    print("[",x, "][", y, "]=", weights[y][x])

weights

!ls sample_data
